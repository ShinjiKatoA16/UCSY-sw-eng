{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72245b3a35aa5abfe2c70cc934b523f87a6b5c72"
   },
   "source": [
    "# Introduction\n",
    "Machine learning competitions are a great way to improve your data science skills and measure your progress. \n",
    "\n",
    "In this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to improve and see how you stack up to others taking this course.\n",
    "\n",
    "The steps in this notebook are:\n",
    "1. Build a Random Forest model with all of your data (**X** and **y**)\n",
    "2. Read in the \"test\" data, which doesn't include values for the target.  Predict home values in the test data with your Random Forest model.\n",
    "3. Submit those predictions to the competition and see your score.\n",
    "4. Optionally, come back to see if you can improve your model by adding features or changing your model. Then you can resubmit to see how that stacks up on the competition leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf513b1a7ef57f4d3b290e8aa8f2fe4f312259c9"
   },
   "source": [
    "## Recap\n",
    "Here's the code you've written so far. Start by running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2cols(df, column, col_vals, prefix):\n",
    "    '''\n",
    "    df: pandas DataFrame\n",
    "    column: string (name of original column)\n",
    "    col_vals: list of string (unique value in original column)\n",
    "    prefix: string\n",
    "    \n",
    "    return: None  (modify df)\n",
    "    '''\n",
    "    \n",
    "    for col_val in col_vals:\n",
    "        df[prefix + col_val] = (df[column] == col_val).astype('int64')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(home_data):\n",
    "    #home_data['Price_per_SF'] = home_data.SalePrice / \\\n",
    "    #                           (home_data['1stFlrSF'] + home_data['2ndFlrSF'] + home_data['TotalBsmtSF'])\n",
    "\n",
    "    str2cols(home_data, 'SaleType', ['WD', 'New', 'COD'], 'ST_')\n",
    "    \n",
    "    sale_condition = ['Normal', 'Abnorml', 'Partial', 'AdjLand', 'Alloca', 'Family']\n",
    "    str2cols(home_data, 'SaleCondition', sale_condition, 'SC_')\n",
    "\n",
    "    bldg = ['1Fam', '2fmCon', 'Duplex', 'TwnhsE', 'Twnhs']\n",
    "    str2cols(home_data, 'BldgType', bldg, 'BT_')\n",
    "    \n",
    "    house_style = ['2Story', '1Story', '1.5Fin', 'SFoyer', 'SLvl']\n",
    "    str2cols(home_data, 'HouseStyle', house_style, 'HS_')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice', 'ST_WD', 'ST_New', 'ST_COD', 'SC_Normal',\n",
       "       'SC_Abnorml', 'SC_Partial', 'SC_AdjLand', 'SC_Alloca', 'SC_Family',\n",
       "       'BT_1Fam', 'BT_2fmCon', 'BT_Duplex', 'BT_TwnhsE', 'BT_Twnhs',\n",
       "       'HS_2Story', 'HS_1Story', 'HS_1.5Fin', 'HS_SFoyer', 'HS_SLvl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "8daa0655d66f7dffe337bd7cc96bedcf1ab9330e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kato/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/kato/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/kato/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/kato/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:67: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for Random Forest Model: 19,180\n",
      "Validation MAE for Linear Regression: 22,006\n",
      "[190483.5 142640.  119175.   78650.  131735. ]\n",
      "[218428. 155531. 107175.  50661. 120946.]\n",
      "258     231500\n",
      "267     179500\n",
      "288     122000\n",
      "649      84500\n",
      "1233    142000\n",
      "Name: SalePrice, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "# Path of the file to read. We changed the directory structure to simplify submitting to a competition\n",
    "iowa_file_path = '../input/train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "add_feature(home_data)\n",
    "# home_data['YearBuilt'] = 2011 - home_data['YearBuilt']  # degrade in RF, no change in LR\n",
    "\n",
    "features = ['OverallQual', 'OverallCond', 'LotArea',\n",
    "            'ST_WD', 'ST_New', 'ST_COD',  'SC_Abnorml', 'SC_Partial', # 'SC_Normal',\n",
    "            'MSSubClass',\n",
    "            'GarageCars', # 'GarageArea',\n",
    "            'YearBuilt',  # 'YearRemodAdd', 'YrSold', \n",
    "            # 'BT_1Fam', 'BT_2fmCon', 'BT_Duplex', 'BT_TwnhsE', 'BT_Twnhs',\n",
    "            # 'HS_2Story', 'HS_1Story', 'HS_1.5Fin', 'HS_SFoyer', 'HS_SLvl',\n",
    "            '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\"\"\"\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Using best value for max_leaf_nodes\n",
    "iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
    "iowa_model.fit(train_X, train_y)\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\"\"\"\n",
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "rf_model.fit(train_X, train_y)\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_Xnorm = scaler.fit_transform(train_X)\n",
    "val_Xnorm = scaler.transform(val_X)\n",
    "\"\"\"\n",
    "svm_model = SVR(kernel='linear')\n",
    "svm_model.fit(train_Xnorm, train_y)\n",
    "svm_val_predict = svm_model.predict(val_Xnorm)\n",
    "svm_val_mae = mean_absolute_error(svm_val_predict, val_y)\n",
    "print('Validation MAE for SVM: {}'.format(svm_val_mae))\n",
    "\"\"\"\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(train_X, train_y)\n",
    "lr_val_predict = lr_model.predict(val_X)\n",
    "lr_val_mae = mean_absolute_error(lr_val_predict, val_y)\n",
    "print('Validation MAE for Linear Regression: {:,.0f}'.format(lr_val_mae))\n",
    "\n",
    "print(rf_val_predictions[:5])\n",
    "print(np.round(lr_val_predict[:5]))\n",
    "print(val_y[:5])\n",
    "#print(val_X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WD       1267\n",
       "New       122\n",
       "COD        43\n",
       "ConLD       9\n",
       "ConLw       5\n",
       "ConLI       5\n",
       "CWD         4\n",
       "Oth         3\n",
       "Con         2\n",
       "Name: SaleType, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_data.SaleType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parm = {'C': 1778.2794100389228, 'epsilon': 562.341325190349} score = -22007.143428777814\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kato/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVR: SVM regressor: linear kernel\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"C\":np.logspace(3, 3.5, 5), \"epsilon\":np.logspace(2, 3, 5)}\n",
    "gridsearch = GridSearchCV(SVR(kernel='linear'), params, cv=4, scoring=\"neg_mean_absolute_error\", return_train_score=True)\n",
    "gridsearch.fit(train_Xnorm, train_y)\n",
    "print(\"Best Parm =\", gridsearch.best_params_, \"score =\", gridsearch.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for SVR linear-kernel: 21,053\n"
     ]
    }
   ],
   "source": [
    "# use best alpha and train using while training data\n",
    "regr = SVR(kernel='linear', C=gridsearch.best_params_[\"C\"], epsilon=gridsearch.best_params_['epsilon'])\n",
    "regr.fit(train_Xnorm, train_y)\n",
    "val_p = regr.predict(val_Xnorm)\n",
    "val_mae = mean_absolute_error(val_y, val_p)\n",
    "print('Validation MAE for SVR linear-kernel: {:,.0f}'.format(val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parm = {'C': 1000000.0, 'epsilon': 5623.413251903491} score = -20942.35949875747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVR: SVM regressor: rbf(Gaussian) kernel\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"C\":np.logspace(6, 7, 5), \"epsilon\":np.logspace(3, 4, 5)}\n",
    "gridsearch = GridSearchCV(SVR(), params, cv=5, scoring=\"neg_mean_absolute_error\", return_train_score=True, n_jobs=-1, verbose=1)\n",
    "gridsearch.fit(train_Xnorm, train_y)\n",
    "print(\"Best Parm =\", gridsearch.best_params_, \"score =\", gridsearch.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for SVR linear-kernel: 17,445\n"
     ]
    }
   ],
   "source": [
    "# use best alpha and train using while training data\n",
    "regr = SVR(C=gridsearch.best_params_[\"C\"], epsilon=gridsearch.best_params_['epsilon'])\n",
    "regr.fit(train_Xnorm, train_y)\n",
    "val_p = regr.predict(val_Xnorm)\n",
    "val_mae = mean_absolute_error(val_y, val_p)\n",
    "print('Validation MAE for SVR linear-kernel: {:,.0f}'.format(val_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7cb35c687dbfe283b3bebb3dfb4217acb507330a"
   },
   "source": [
    "# Creating a Model For the Competition\n",
    "\n",
    "Build a Random Forest model and train it on all of **X** and **y**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "971d9642c4a707a52f93caaca01a0dff2b0907b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kato/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To improve accuracy, create a new Random Forest model which you will train on all training data\n",
    "rf_model_on_full_data = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# fit rf_model_on_full_data on all data from the \n",
    "rf_model_on_full_data.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kato/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/kato/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1000000.0, cache_size=200, coef0=0.0, degree=3,\n",
       "  epsilon=5623.413251903491, gamma='auto_deprecated', kernel='rbf',\n",
       "  max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit with SVR\n",
    "\n",
    "Xnorm = scaler.transform(X)\n",
    "regr.fit(Xnorm, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbd740853c59245550529e5fd0fbd62e3b4f4ff8"
   },
   "source": [
    "# Make Predictions\n",
    "Read the file of \"test\" data. And apply your model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "cda52be4bccd52aec3eb7f9cf523297a1573ba57"
   },
   "outputs": [],
   "source": [
    "# path to file you will use for predictions\n",
    "test_data_path = '../input/test.csv'\n",
    "\n",
    "# read test data file using pandas\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "test_data['GarageCars'].fillna(0.0, inplace=True)\n",
    "add_feature(test_data)\n",
    "\n",
    "# create test_X which comes from test_data but includes only the columns you used for prediction.\n",
    "# The list of columns is stored in a variable called features\n",
    "test_X = test_data[features]\n",
    "\n",
    "# make predictions which we will submit. \n",
    "test_preds = rf_model_on_full_data.predict(test_X)\n",
    "\n",
    "# The lines below shows you how to save your data in the format needed to score it in the competition\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': test_preds})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kato/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_Xn = scaler.transform(test_X)\n",
    "test_preds = regr.predict(test_Xn)\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': test_preds})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1459 entries, 0 to 1458\n",
      "Data columns (total 17 columns):\n",
      "OverallQual     1459 non-null int64\n",
      "OverallCond     1459 non-null int64\n",
      "LotArea         1459 non-null int64\n",
      "ST_WD           1459 non-null int64\n",
      "ST_New          1459 non-null int64\n",
      "ST_COD          1459 non-null int64\n",
      "SC_Abnorml      1459 non-null int64\n",
      "SC_Partial      1459 non-null int64\n",
      "MSSubClass      1459 non-null int64\n",
      "GarageCars      1459 non-null float64\n",
      "YearBuilt       1459 non-null int64\n",
      "1stFlrSF        1459 non-null int64\n",
      "2ndFlrSF        1459 non-null int64\n",
      "FullBath        1459 non-null int64\n",
      "BedroomAbvGr    1459 non-null int64\n",
      "KitchenAbvGr    1459 non-null int64\n",
      "TotRmsAbvGrd    1459 non-null int64\n",
      "dtypes: float64(1), int64(16)\n",
      "memory usage: 193.9 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data.GarageCars.fillna(0, inplace=True)\n",
    "test_data[features].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac1a3da971c7884eef796d3be458a65dcd361b3d"
   },
   "source": [
    "# Test Your Work\n",
    "After filling in the code above:\n",
    "1. Click the **Commit and Run** button. \n",
    "2. After your code has finished running, click the small double brackets **<<** in the upper left of your screen.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n",
    "3. Go to the output tab at top of your screen. Select the button to submit your file to the competition.  \n",
    "4. If you want to keep working to improve your model, select the edit button. Then you can change your model and repeat the process.\n",
    "\n",
    "Congratulations, you've started competing in Machine Learning competitions.\n",
    "\n",
    "# Continuing Your Progress\n",
    "There are many ways to improve your model, and **experimenting is a great way to learn at this point.**\n",
    "\n",
    "The best way to improve your model is to add features.  Look at the list of columns and think about what might affect home prices.  Some features will cause errors because of issues like missing values or non-numeric data types. \n",
    "\n",
    "Level 2 of this course will teach you how to handle these types of features. You will also learn to use **xgboost**, a technique giving even better accuracy than Random Forest.\n",
    "\n",
    "\n",
    "# Other Courses\n",
    "The **[Pandas course](https://kaggle.com/Learn/Pandas)** will give you the data manipulation skills to quickly go from conceptual idea to implementation in your data science projects. \n",
    "\n",
    "You are also ready for the **[Deep Learning](https://kaggle.com/Learn/Deep-Learning)** course, where you will build models with better-than-human level performance at computer vision tasks.\n",
    "\n",
    "---\n",
    "**[Course Home Page](https://www.kaggle.com/learn/machine-learning)**\n",
    "\n",
    "**[Learn Discussion Forum](https://kaggle.com/learn-forum)**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
